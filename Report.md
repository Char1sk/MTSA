# Report

## Part 1. Dataset

### 1.1. CustomDataset Class

鉴于文件中已给出ETTDataset的实现，且其他数据集与ETT数据集的内容格式相差不大、仅文件结构有所不同，因此CustomDataset的实现主要参考ETTDataset。

**read_data**：使用pandas库将数据读入，并按照时间、特征、目标这三个属性将列分开。按照格式要求，返回不含时间的特征-目标数据，并在第0维添加1维，即(n_samples, timesteps, channels)。

**split_data**：按照给定的训练集、验证集、测试集比例，对数据集进行划分。参考ETTDataset实现方式，不对数据集进行打乱，直接按照文件内容顺序对数据集进行按比例划分。

### 1.2. Data Visiualize

**数据处理**：输入数据可能为(n_samples, timesteps, channels)或(n_samples, timesteps)，要首先对维度处理来统一后续操作。由于n_samples始终为1（因为该参数并非来自于数据集本身，而始终来自于Dataset类中的expand_dims操作），因此直接对第0维进行squeeze操作。而对单通道的数据集，此时数据维度仅有一维，因此在第1维处expand_dims即可。此时，数据形状统一为(timesteps, channels)。

**可视化时间范围**：函数输入参数t已指明要可视化的点数量，因此要从数据集中挑选t个点进行呈现。此处实现选择在[0, T-t)区间内均匀地随机选取一个整数ridx，并选取[ridx, ridx+t)区间内的点进行可视化。

**绘制特征-目标关系**：对于多通道数据集，考虑对每个特征单独绘制分析其与目标的变化关系。由于其至少包含特征通道和目标通道，即data_cols>=2，因此对[0, data_cols-1)内的第任意个特征，在一张图上绘制其与目标的变化趋势，即对第c列和第最后一列的数据绘制。由于二者取值范围差距较大，使用twinx函数使得纵轴对二者分别划分取值间隔。对于单通道数据集，其只有目标一列，data_cols-1==0，因此不会进行特征-目标关系的绘制。

**绘制所有通道关系**：有时需要反应多变量关系，因此将所有通道曲线绘制于同一张图上。因为其取值范围差距大，所以均将其归一化至[0.0, 1.0]的范围内，只关注趋势相关的信息；其他诸如对数纵轴、截断纵轴等方法均不太适用。但对有些通道过多(数百个)的数据集，同时绘制所有通道后图片过于复杂，并不直观。

### 1.3. Testing

> 在项目根目录执行python ./src/dataset/dataset.py即可测试

**测试代码实现**：通过get_dataset函数构造CustomDataset对象并调用其read_data和split_data函数，未报错则说明实现部分正确。通过访问输出dataset对象的data_cols、shape、数值等，验证数据集读取的正确性；通过访问训练集、验证集、测试集的大小，验证数据集划分的正确性。通过调用data_visualize函数，保存可视化结果，验证实现正确性并分析数据集性质。

**数据性质分析**：对exchange_rate数据集进行可视化。下图中的每个小图是可视化的呈现结果。第一张图是所有通道的图像；第2~8张图分别是第0~6个特征-目标的图像，红色线条为目标曲线、蓝色线条为特征曲线。特征0、特征5、特征6总体和目标呈正相关，其中特征0尤其吻合；特征1、特征2和目标略微呈负相关；特征3、特征4和目标没有太明显的趋势。第1张图中不太能看出太明显的关系，在只有7个特征的情况下就已经比较杂乱了。

![](./pics/set.png)

## Part 2. Transform

> 在项目根目录执行python ./src/utils/transforms.py即可测试

**归一化Normalization**：将数据取值限制在[0, 1]之间。为实现逆变换，在正向变换时储存数据的最大值和最小值即可。公式如下：
$$
y_t' = \frac{y_t-y_{\min}}{y_{\max}-y_{\min}}
$$

**标准化Standardization**：将数据变换成0均值和标准方差。为实现逆变换，在正向变换时储存数据的均值和标准差即可。公式如下：
$$
z_t = \frac{y_t-\mu}{\sigma}
$$

**平均归一化Normalization**：将数据取值均值化为0。为实现逆变换，在正向变换时储存数据的最大值、最小值和均值即可。公式如下：
$$
y_t' = \frac{y_t-\mu}{y_{\max}-y_{\min}}
$$

**Box-Cox变换(Yeo-Johnson版本)**：适用于数值值域较大、呈现季节性变换的情况，用于分布正态程度矫正。原始版本只针对非负序列，采用Yeo-Johnson方式拓展范围。由于该变换不改变正负性，也不和统计量相关，因此实现逆变换不用存储数据，直接分段计算即可。公式如下：
$$
y^{(\lambda)}_t = \begin{cases}
 [(y_t+1)^\lambda-1]/\lambda              & \text{ if } \lambda\neq 0, y\ge0\\
 \log(y_t+1)                              & \text{ if } \lambda = 0, y\ge0\\
 -[(-y_t+1)^{(2-\lambda)}-1]/ (2-\lambda) & \text{ if } \lambda\neq 2, y\lt0\\
 -\log(-y_t+1)                            & \text{ if } \lambda = 2, y\lt0
\end{cases}
$$

## Part 3. Metrics

**MAE**：平均绝对误差。公式如下：
$$
\mathrm{MAE} = \frac{1}{H} \sum_{i=1}^H |y_{n+i}-\hat{y}_{n+i}|
$$

**MAPE**：平均百分比绝对误差。注意此处分母有可能取0，本次实现选择跳过分母为0的点。公式如下：
$$
\mathrm{MAPE} = \frac{100}{H} \sum_{i=1}^H \frac{|y_{T+i}-\hat{y}_{T+i}|}{|y_{T+i}|}
$$

**SMAPE**：对称平均百分比绝对误差。此处分母依然有可能取0，该情况下使分母加上一个很小的数，使该项分式为0即可。公式如下：
$$
\mathrm{SMAPE} = \frac{200}{H} \sum_{i=1}^H \frac{|y_{T+i}-\hat{y}_{T+i}|}{|y_{T+i}|+|\hat{y}_{T+i}|}
$$

**MASE**：平均绝对缩放误差，需要考虑数据周期m，此处取24。分母暂不考虑为0的可能性，因其情况过于特殊。公式如下：
$$
\mathrm{SMAPE} = \frac{1}{H} \sum_{i=1}^H \cfrac{|y_{T+i}-\hat{y}_{T+i}|}{\cfrac{1}{T+H-m}\sum_{j=m+1}^{T+H}|y_j-y_{j-m}|}
$$


## Part 4. Models

### 4.1. Implementation

本节的所有模型均采用自回归，即只考虑此前输出的影响，不考虑此前的输入特征。

**线性回归LR**：该模型建立输入变量与目标输出之间的线性关系。由于是自回归，则只需建立seq_len维此前输出X到pred_len维目标输出Y的关系即可，公式为$Y=X\theta$。线性回归存在闭式解，其最优参数为$\hat\theta=(X^TX)^{-1}X^TY$。

**指数平滑ES**：该模型用此前输出的指数平均来作为接下来输出的预测。该方法不需要训练过程，只需在预测时计算指数平均即可。其公式为$\hat{Y}_{N+l|N}=c\sum_{j=0}^{N-1} \lambda^j Y_{N-j}$，其中c使权重之和取1。此外，也可利用递推公式：$\hat{Y}_{N+2|N+1}=(1-\lambda)Y_{N+1}+\lambda\hat{Y}_{N+1|N}$。在预测的时间长度不为1时，多次重复最终的指数平均值即可。

### 4.2. Testing

> 在项目根目录执行python ./main.py --job test

此处测试在exchange_rate数据集上进行，观察LR和ES模型在不同变换下的各指标效果。结果如下表所示。

各个变换对LR和ES的影响均几乎可忽略不计。对于LR来说，大部分变换均是线性变换，应当仅等效于对权重进行了缩放和平移，此处出现的误差可能是浮点误差或求矩阵逆运算等导致的；对于ES来说，只需要计算数据的指数平均即可，进行变换和逆变换后也应当不影响最终结果。从总体上分析，在该数据集上，ES的效果略优于LR。

所有数据集、所有模型、所有变换的全部结果可见文末附表。

| Dataset | Model | Transform | MSE  | MAE  | MAPE | SMAPE | MASE |
| ------- | ----- | --------- | ---- | ---- | ---- | ----- | ---- |
|exchange_rate|LinearRegression|Identity|0.00037938|0.014626|1.9041|1.9021|0.81060|
|||Normalization|0.00037942|0.014625|1.9041|1.9018|0.81054|
|||Standardization|0.00037540|0.014541|1.8930|1.8903|0.80586|
|||MeanNormalization|0.00037540|0.014541|1.8930|1.8903|0.80586|
|||BoxCox|0.00037938|0.014626|1.9041| 1.9021 |0.81060|
||ExponantialSmoothing|Identity|0.00036042|0.014237|1.8584|1.8559|0.78902|
|||Normalization|0.00036042|0.014237|1.8584|1.8559|0.78902|
|||Standardization|0.00036042|0.014237|1.8584|1.8559|0.78902|
|||MeanNormalization|0.00036042|0.014237|1.8584|1.8559|0.78902|
|||BoxCox| 0.00036042 |0.014237|1.8584|1.8559|0.78902|


## Part 5. TsfKNN

### 5.1. Distance Metrics

**曼哈顿距离**：即L0范数，公式为：
$$
d(x,y) = \sum_{t=1}^n |x_t-y_t|
$$

**切比雪夫距离**：即L$\infin$范数，公式为：
$$
d(x,y) = \lim_{p\rarr+\infin}(\sum_{t=1}^n |x_t-y_t|^p)^{1/p}
$$

**余弦相似度**：衡量两向量之间的夹角大小，公式为：
$$
d(x,y) = \frac{\vec x \cdot \vec y}{|\vec x|\cdot|\vec y|} = \frac{\sum x_ty_t}{\sqrt{\sum x_t^2} \sqrt{\sum y_t^2}}
$$

**动态时间规整DTW**：该指标先将两个序列尽可能进行对齐，即选择是否对其中一个序列的上一个采样点进行重复，最后再计算距离指标(此处选择欧氏距离)。该距离实现采用动态规划，其递推公式如下所示，最终求得DTW(l,l)即为距离。
$$
DTW(i,j) = d(x_i,y_j) +\min \begin{cases}
 DTW(i,j-1)  &  \mathrm{repeat}\ x_i\\
 DTW(i-1,j)  &  \mathrm{repeat}\ y_i\\
 DTW(i,j)    &  \mathrm{repeat}\ \mathrm{neither}
\end{cases}
$$

### 5.2. Approximate KNN

**局部敏感哈希LSH**：采用哈希函数，对多维向量进行哈希并将其映射到数个区间中的一个(即一个桶)。在近似KNN时，先对训练数据构建完整的哈希表，再对查询数据进行哈希，并认为其映射到的区间(桶)中的所有数据均为其近邻。也可以在此时对这些数据进行筛选，选取k个距离最近的数据作为近邻，避免FP的情况。由于哈希函数需要保证，两向量足够接近时哈希到同一值的概率足够大、两向量足够远离时哈希到同一值的概率足够小。所以采用多个哈希函数，每个哈希函数独立建立和查询哈希表，每个哈希函数查询所得近邻的并集即最后的候选近邻，以避免随机导致FN的情况。

**实现近似KNN**：哈希函数采用标准正态分布随机向量与输入向量作积，哈希输出k位的结果，即每个哈希表有$2^k$个桶。为保证训练数据在桶中较均匀的分布，在哈希前需要临时进行零均值化，从而避免无近邻从而无法预测、或者近邻太多导致速度降低。哈希的公式为：$h=(\vec x-\vec \mu)\cdot \vec n$。哈希表采用数组实现，将k位哈希值转换为对应的十进制数值即可；桶用列表实现，桶内的元素记录数据的索引即可。查询时，根据哈希函数获取所有近邻的索引，并计算与所有近邻的距离，排序并选出前k个即可。

### 5.3. Testing

> 在项目根目录执行python ./main.py --job knn_test

此处测试在illness和ETTh1数据集上进行，观察KNN和LSH近似下的各指标效果和运算时间。结果如下表所示。

**illness**数据集较小(约1000条数据)，是否近似优化对执行时间的差距较少，但LSH近似下运行速度依然较快。由于目标数据的绝对值较大，计算得出的MSE和MAE值较大，但其他的指标值相对较低；是否近似对指标没有显著影响。**ETTh1**数据集较大(约17000条数据)，在近似优化后速度能提升8倍左右(若不进行零均值化则只提升2倍左右)；各评价指标依然没有显著差距。

| Dataset | Model    | Time(s) | MSE      | MAE     | MAPE  | SMAPE | MASE  |
| ------- | -------- | ------- | -------- | ------- | ----- | ----- | ----- |
| illness | KNN      | 0.04693 | 2.31e+11 | 4.26e+5 | 34.6  | 43.4  | 1.44  |
|         | KNN(LSH) | 0.02850 | 2.38e+11 | 4.31e+5 | 34.9  | 44.0  | 1.45  |
| ETTh1   | KNN      | 39.11   | 18.51    | 3.415   | 105.1 | 55.42 | 2.053 |
|         | KNN(LSH) | 5.058   | 18.11    | 3.411   | 103.7 | 55.51 | 2.051 |

## *Appendix

| Dataset | Model    | Time(s) | MSE      | MAE     | MAPE  | SMAPE | MASE  |
| ------- | -------- | ------- | -------- | ------- | ----- | ----- | ----- |
|electricity|ZeroForecast|Identity|11073328.676295878|3282.642192530586|100.0|199.97424327495224|12.406699707407457|
|||Normalization|11073328.676295878|3282.642192530586|100.0|199.97424327495224|12.406699707407457|
|||Standardization|297590.8397576387|428.85910672756427|12.974976976467573|12.886515690563261|1.6208669242303715|
||                      |MeanNormalization|297590.8397576387|428.85910672756427|12.974976976467573|12.886515690563261|1.6208669242303715|
|||BoxCox|11073328.676295878|3282.642192530586|100.0|199.97424327495224|12.406699707407457|
||MeanForecast|Identity|266797.77002027887|419.3002445703209|12.678205017121453|12.568220417905565|1.584739339993725|
|||Normalization|266797.77002027887|419.3002445703209|12.678205017121453|12.568220417905565|1.584739339993725|
|||Standardization|266797.77002027887|419.3002445703209|12.678205017121453|12.568220417905565|1.584739339993725|
|||MeanNormalization|266797.77002027887|419.3002445703209|12.678205017121453|12.568220417905565|1.584739339993725|
|||BoxCox|266797.77002027887|419.3002445703209|12.678205017121453|12.568220417905565|1.584739339993725|
||LinearRegression|Identity|98069.3348865191|227.64452770707229|6.839167276278903|6.805821268469479|0.8603792706140108|
|||Normalization|98069.33488652346|227.6445277070792|6.839167276277404|6.805821268469827|0.8603792706140367|
|||Standardization|96918.38391814745|226.11357315542125|6.8064539540421185|6.758082851901577|0.8545930495536581|
|||MeanNormalization|96918.38391814718|226.11357315542065|6.806453954042101|6.758082851901557|0.8545930495536557|
|||BoxCox|98069.3348865191|227.64452770707229|6.839167276278903|6.805821268469479|0.8603792706140108|
||ExponantialSmoothing|Identity|355527.33214851626|454.01285205127795|13.580467272629484|13.48140449964162|1.7159351486801837|
|||Normalization|355527.33214851626|454.01285205127795|13.580467272629484|13.48140449964162|1.7159351486801837|
|||Standardization|355527.33214851626|454.01285205127795|13.580467272629484|13.48140449964162|1.7159351486801837|
|||MeanNormalization|355527.33214851626|454.0128520512779|13.580467272629484|13.48140449964162|1.7159351486801837|
|||BoxCox|355527.33214851626|454.01285205127795|13.580467272629484|13.48140449964162|1.7159351486801837|
|exchange_rate|ZeroForecast|Identity|0.6021271415013613|0.7733755211627907|100.0|199.9994791161788|42.85986355557416|
|||Normalization|0.025986471221270017|0.14821952116279066|18.591481663281915|20.819211947437374|8.214209371093537|
|||Standardization|0.004017502113435572|0.05331671807529295|7.100045997390779|6.974124529540367|2.9547706119561306|
|||MeanNormalization|0.004017502113435572|0.05331671807529295|7.100045997390779|6.974124529540367|2.9547706119561306|
|||BoxCox|0.6021271415013613|0.7733755211627907|100.0|199.9994791161788|42.85986355557416|
||MeanForecast|Identity|0.0008822400486414172|0.023624823831455907|3.0907839804967265|3.072151912704365|1.3092691690296465|
|||Normalization|0.0008822400486414171|0.02362482383145591|3.0907839804967274|3.072151912704365|1.3092691690296467|
|||Standardization|0.0008822400486414172|0.023624823831455914|3.0907839804967274|3.072151912704365|1.309269169029647|
|||MeanNormalization|0.0008822400486414172|0.023624823831455914|3.0907839804967274|3.072151912704365|1.3092691690296467|
|||BoxCox|0.000882240048641417|0.023624823831455907|3.0907839804967265|3.072151912704365|1.3092691690296467|
||LinearRegression|Identity|0.0003793819535651787|0.014626843476102767|1.9041626322451506|1.9021937035677654|0.8106081696145969|
|||Normalization|0.00037942891345293163|0.014625695537934972|1.9041188946693623|1.901879237037681|0.8105445517835488|
|||Standardization|0.000375406931727823|0.0145412809882074|1.893049436496995|1.8903411436265707|0.8058663637824739|
|||MeanNormalization|0.0003754069317278718|0.014541280988210885|1.8930494364974422|1.8903411436270359|0.8058663637826669|
|||BoxCox|0.0003793819535708008|0.014626843476487404|1.9041626322863665|1.9021937036276613|0.8106081696359131|
||ExponantialSmoothing|Identity|0.0003604234854087166|0.01423743509016369|1.858439811760508|1.855921973657592|0.789027462917737|
|||Normalization|0.00036042348540871644|0.014237435090163687|1.8584398117605083|1.8559219736575923|0.7890274629177371|
|||Standardization|0.00036042348540871644|0.01423743509016369|1.858439811760508|1.8559219736575923|0.7890274629177371|
|||MeanNormalization|0.00036042348540871644|0.01423743509016369|1.858439811760508|1.8559219736575923|0.7890274629177371|
|||BoxCox|0.00036042348540871655|0.014237435090163689|1.8584398117605083|1.855921973657592|0.7890274629177371|
|illness|ZeroForecast|Identity|1393485874768.303|1154722.6951687117|100.0|199.9999999996362|3.8979187694119544|
|||Normalization|426296632979.88116|605140.6951687117|50.02076662645406|68.21332078501673|2.0427322366678577|
|||Standardization|104246236096.19443|266991.54075061623|21.438191263905633|24.084210588304142|0.9012651629004229|
|||MeanNormalization|104246236096.19443|266991.54075061623|21.438191263905633|24.084210588304142|0.9012651629004229|
|||BoxCox|1393485874768.303|1154722.6951687117|100.0|199.9999999996362|3.8979187694119544|
||MeanForecast|Identity|83001121836.04764|248561.73117570937|20.78808828553637|23.072301469173446|0.8390529097254542|
|||Normalization|83001121836.04764|248561.73117570937|20.788088285536375|23.072301469173446|0.8390529097254542|
|||Standardization|83001121836.04764|248561.73117570937|20.78808828553637|23.072301469173446|0.8390529097254542|
|||MeanNormalization|83001121836.04764|248561.73117570937|20.78808828553637|23.072301469173446|0.8390529097254542|
|||BoxCox|83001121836.04764|248561.73117570937|20.78808828553637|23.072301469173446|0.8390529097254542|
||LinearRegression|Identity|36205847571.735344|127214.99791195337|11.859308462945945|11.530198306986525|0.4294310055448037|
|||Normalization|37682916275.62825|134622.6891630472|12.482368937064141|12.29679461239946|0.4544366444626642|
|||Standardization|38783790314.68184|138777.59085475063|12.84653285683606|12.739404146079366|0.4684620631687422|
|||MeanNormalization|38783790314.68225|138777.59085475374|12.846532856836212|12.739404146079163|0.4684620631687528|
|||BoxCox|36205847571.735344|127214.99791195337|11.859308462945945|11.530198306986525|0.4294310055448037|
||ExponantialSmoothing|Identity|87549261897.23706|227724.8443419773|20.34648104775113|20.96671707344059|0.7687152497616043|
|||Normalization|87549261897.23706|227724.8443419773|20.34648104775113|20.96671707344059|0.7687152497616043|
|||Standardization|87549261897.23708|227724.8443419773|20.34648104775113|20.96671707344059|0.7687152497616043|
|||MeanNormalization|87549261897.23708|227724.8443419773|20.34648104775113|20.96671707344059|0.7687152497616043|
|||BoxCox|87549261897.23706|227724.8443419773|20.34648104775113|20.96671707344059|0.7687152497616043|
|traffic|ZeroForecast|Identity|0.0018417066288081566|0.03642731713548763|100.0|199.93766628092865|6.389440604997737|
|||Normalization|0.0018417066288081566|0.03642731713548763|100.0|199.93766628092865|6.389440604997737|
|||Standardization|0.0005147689272760532|0.01958157177081136|145.09335910169568|62.302669236469164|3.434655627169747|
|||MeanNormalization|0.0005147689272760532|0.01958157177081136|145.09335910169568|62.302669236469164|3.434655627169747|
|||BoxCox|0.0018417066288081566|0.03642731713548763|100.0|199.93766628092865|6.389440604997737|
||MeanForecast|Identity|0.0005291181547421401|0.019839954833905164|146.50890880550548|62.91583983217315|3.479976648996163|
|||Normalization|0.0005291181547421401|0.019839954833905164|146.50890880550548|62.91583983217315|3.479976648996163|
|||Standardization|0.0005291181547421401|0.019839954833905164|146.50890880550548|62.91583983217315|3.479976648996163|
|||MeanNormalization|0.0005291181547421401|0.019839954833905164|146.50890880550548|62.91583983217315|3.479976648996163|
|||BoxCox|0.0005291181547421401|0.019839954833905164|146.5089088055055|62.91583983217315|3.479976648996163|
||LinearRegression|Identity|6.733475331629307e-05|0.005627611165676765|22.985692406649555|20.320698549913768|0.9870967756800305|
|||Normalization|6.733475331629304e-05|0.005627611165676666|22.985692406652923|20.320698549913775|0.9870967756800132|
|||Standardization|6.72335729568242e-05|0.005617924993532944|23.123755747060223|20.259856710279745|0.9853977973728293|
|||MeanNormalization|6.723357295682425e-05|0.005617924993532958|23.12375574706164|20.25985671028001|0.9853977973728316|
|||BoxCox|6.73347533162933e-05|0.005627611165676719|22.985692406652433|20.320698549914233|0.9870967756800224|
||ExponantialSmoothing|Identity|0.0009263791854696012|0.024520852551925643|153.98053448790856|77.37993047657261|4.301017568263437|
|||Normalization|0.0009263791854696012|0.024520852551925643|153.98053448790856|77.37993047657258|4.301017568263437|
|||Standardization|0.0009263791854696014|0.024520852551925643|153.98053448790853|77.37993047657261|4.301017568263437|
|||MeanNormalization|0.0009263791854696012|0.024520852551925643|153.98053448790853|77.37993047657258|4.301017568263437|
|||BoxCox|0.0009263791854696014|0.02452085255192564|153.98053448790853|77.37993047657258|4.301017568263437|
|weather|ZeroForecast|Identity|188334.63094656693|433.5797126084045|100.0|199.99999907581326|46.11036398274221|
|||Normalization|2448.2117900100443|45.87971260840454|10.42320027113616|11.078291626835949|4.879218714063361|
|||Standardization|343.26499121115904|14.692713612618487|3.3568166651875204|3.369845206392058|1.5625416800437666|
|||MeanNormalization|343.26499121115904|14.692713612618487|3.3568166651875204|3.369845206392058|1.5625416800437666|
|||BoxCox|188334.63094656693|433.5797126084045|100.0|199.99999907581326|46.11036398274221|
||MeanForecast|Identity|294.56463586212493|12.311206472953334|2.8225483282265187|2.8187264821766433|1.3092730010808313|
|||Normalization|294.564635862125|12.311206472953334|2.8225483282265187|2.8187264821766433|1.3092730010808313|
|||Standardization|294.564635862125|12.311206472953337|2.8225483282265187|2.8187264821766433|1.3092730010808313|
|||MeanNormalization|294.564635862125|12.311206472953337|2.8225483282265182|2.8187264821766433|1.3092730010808313|
|||BoxCox|294.56463586212493|12.311206472953334|2.8225483282265187|2.8187264821766433|1.3092730010808313|
||LinearRegression|Identity|2631.6603509200454|45.56261079500872|10.45234648282351|11.189279779467658|4.845495549417796|
|||Normalization|145.81985056493008|8.101768836875404|1.8532496533343799|1.85244163269533|0.8616074486625356|
|||Standardization|138.76130916261098|8.200665979268072|1.874112078331083|1.8766674971837667|0.872124968509452|
|||MeanNormalization|138.761309162611|8.200665979268067|1.874112078331083|1.876667497183766|0.8721249685094509|
|||BoxCox|2631.6603509200454|45.56261079500872|10.45234648282351|11.189279779467661|4.845495549417796|
||ExponantialSmoothing|Identity|135.3614519976225|7.046614540213054|1.6170569400165726|1.6072353513975457|0.7493938296618753|
|||Normalization|135.36145199762248|7.046614540213056|1.6170569400165733|1.6072353513975464|0.7493938296618756|
|||Standardization|135.3614519976225|7.046614540213056|1.6170569400165733|1.6072353513975464|0.7493938296618757|
|||MeanNormalization|135.3614519976225|7.046614540213057|1.6170569400165733|1.6072353513975464|0.7493938296618757|
|||BoxCox|135.3614519976225|7.046614540213054|1.6170569400165726|1.6072353513975457|0.7493938296618753|
|











